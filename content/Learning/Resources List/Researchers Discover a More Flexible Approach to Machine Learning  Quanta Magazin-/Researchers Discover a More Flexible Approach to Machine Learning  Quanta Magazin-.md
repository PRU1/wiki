---
Status:
  - Finished
Date Viewed: 2023-07-14
Link: https://www.quantamagazine.org/researchers-discover-a-more-flexible-approach-to-machine-learning-20230207/
Type: Article
ee:
  - EE
---
- Right now AI is inflexible in adjusting to unfamiliar circumstances.
- 2020 MIT researchers introduced a new kind of neural network
- Inspired by groundwork, Caenorhabditis elgans, to produce what they call “liquid neural networks”
- Liquid neural networks run faster and more accurately than continuous-time neural networks
- Ramin Hasani and Mathias Lechner “realized years ago that […] can” be used to make resilient neural networks that can account for unexpected inputs
- worm studied has a fully mapped-out nervous system
- Better than traditional neural networks since they solve “an entire ensemble of linked equations, allowing it to characterize the state of the system at any given moment”. traditional neural networks only give results at a particular moment in time.

![[/Untitled 13.png|Untitled 13.png]]

- instead of having discrete (or deterministic?) weights, the weights are nonlinear and probabilistic.
- Liquid neural networks are able to retrain based on input they receive; neural networks right now cannot (once they are trained, you use it)
- Advantage: twisty roads
- Hasani said their neural networks could handle “enormous inputs without going haywire”

> They are complex enough to allow interesting things to happen, but not so complex as to lead to chaotic behavior.”

> “Neural networks are developing to the point that the very ideas we’ve drawn from nature may soon help us understand nature better.”