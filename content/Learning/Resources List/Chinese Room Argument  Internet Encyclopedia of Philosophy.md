---
Link: https://iep.utm.edu/chinese-room-argument/
ee:
  - EE
---
- thought experiment by John Searle
- counters the idea that AI can think
- argument is based on two claims
    - brains cause minds
    - syntax doesn’t suffice for semantics
    - Strong AI: “the compute is not merely a tool in the study of the mind, rather the appropriately programmed computer really is a mind in the sense that computers given the right programs can be literally said to understand and have other cognitive states” ~ Searle
    - Weak AI: computers merely simulate thought

## The Chinese Room Thought Experiment

- imagine you are a monolingual English speaker
- you’re locked in a room and are given a bunch of Chinese writing
- and a second batch of Chinese script
- and a set of rules in English meant to correlate the second batch with the first batch
- the rules “correlate one set of formal symbols with another set of formal symbols”, where formal means you can identify the symbol entirely by its shape
- Then you have a 3rd batch of Chinese symbols and more instructions in English to “correlate elements of this third batch with elements of the first two batches”
- they instruct you to give back “certain sorts of Chinese symbols with certain sorts of shapes in response”.
- Those giving you the symbols → call the first batch a script [ a data structure that can process natural language ]
- the second batch is called the story batch
- the third batch is the questions back —> the symbols you give back “the call answers to the questions”
- the person outside the door cannot tell that you do not speak Chinese
- In fact, you don’t know what you are writing, you’re just following the rule book
- this suggests that an AI can do something without understanding what it’s actually doing
- and this would pass the Turing test